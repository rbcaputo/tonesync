# DSP Reference - Signal Processing Mathematics
This document describes the pure mathematical foundations of ToneSync's audio engine.\
All content here is domain-agnostic signal theory with no claims or interpretations.

---

## 1. The Core Abstraction
Every signal generated by ToneSync follows this model:
```mathematics
x(t) = E(t) ∑(i=1 to N) w_i C_i(t) M_i(t)
```
Where:
* `E(t)` = macro envelope (minutes-scale amplitude shaping)
* `C_i(t)` = carrier signal(s) – audible waveform
* `M_i(t)` = modulation signal(s) – amplitude variation
* `w_i` = layer weights – mixing coefficients
* `N` = number of layers

This abstraction subsumes:
* Amplitude modulated tones
* Pure sine/harmonic drones
* Layered audio textures
* Noise beds

---

## 2. Carrier Model
A carrier is any audible waveform in the 20-2000Hz range.

### 2.1 Pure Sine Carrier
```mathematics
C(t) = sin(2πf_c t + ϕ)
```
Where:
* `f_c` = carrier frequency (typically 100-800Hz)
* `ϕ` = initial phase (usually 0)

### 2.2 Harmonic Carrier
```mathematics
C(t) = ∑(k=1 to K) a_k sin(2πkf_c t)
```
**Why harmonics matter:**
* Reduces listening fatigue compared to pure sine
* Provides perceptual "fullness"
* Maintains mathematical cleanliness
* Still deterministic and controllable

---

## 3. Modulation Model
Modulation creates time-varying amplitude changes.

### 3.1 Amplitude Modulation (Smooth)
```mathematics
M(t) = 1 + α sin(2πf_m t)
```
**Constraints:**
* `0 ≤ α ≤ 1` modulation depth
* `f_m ∈ [0.1, 100]Hz` modulation frequency
* `[1-α, 1+α]` output range

This is the **default modulator** for smooth amplitude variation.

## 3.2 Hard Gating (Isochronic-style)
```mathematics
M(t) = gate(f_m, d)
```
Where:
* `gate` is a square wave at frequency `f_m`
* `d` is duty cycle (typically 0.3-0.7)

This prevents harsh click artifacts while maintaining rhythmic character.

---

## 4. Envelope Model (Critical for long sessions)
No audio system omits this. Envelopes prevent startle responses and clicks.

### 4.1 Exponential Fade-In/Fade-Out
```mathematics
       ⎧ 1 - e^(-t/τ_a)      t< T_on
E(t) = ⎨ 1                   T_on ≤ t ≤ T_off
       ⎩ e^(-(t-T_off)/τ_r)  t > T_off
```
Where:
* `τ_a` = attack time constant (typically 10-30 seconds)
* `τ_r` = release time constant (typically 30-60 seconds)

**Why so slow?**\
Human auditory startle response requires gradual transitions.

### 4.2 Macro Envelopes (session shaping)
Long-form sessions benefit from slow amplitude drift:
```mathematics
E_macro(t) = 0.5 + 0.5 sin(2πf_macro t)
```
Where:
* `f_macro ≪ 1 Hz` one cycle every 10-30 minutes

This prevents perceptual adaptation and maintains engagement.

---

## 5. Layering Model
Multiple layers combine additively:
```mathematics
x(t) = ∑(i=1 to N) E_i(t) C_i(t) M_i(t)
```
Typical layer configuration:
* **Low carrier + slow modulation** – felt presence
* **Mid carrier + harmonic stack** – tonal body
* **High carrier (optional)** – clarity
* **Noise bed (optional)** – masking repetition

Example noise carrier:
```mathematics
C_noise(t) = pink_noise()
```

---

# 6. Stability Constraints (real-time audio)
A generator that **wanders** breaks perceptual coherence.

### Rules
* Carrier frequencies are fixed or glide slowly
* Modulation frequency does not jitter
* Phase resets are avoided
* No sudden parameter jumps

Mathematically:
```
df/dt ≈ 0
```
Unless deliberately ramped with smoothing.1

---

## 7. Minimal Parameter Set
Strip everything down to essentials:
* Carrier frequency `f_c`
* Modulation frequency `f_m`
* Modulation depth `α`
* Envelope attack/release times
* Layer weights `w_i`
* Stereo offset (optional, for binaural effects)

---

## 8. System Design Principle
We generate:
> Slowly varying, low-information audio fields that the auditory system can synchronize to without resistance.
This system works because:
* The signal is **predictable**
* The changes are **slow**
* The brain doesn't **fight** it

---

## DSP Graph Architecture

### 1. Global Frame
All nodes operate in discrete time:
* Sample rate: `f_s` (e.g., 48,000 Hz)
* Time step: `Δt = 1/f_s`
* Sample index: `n`
* Continuous time: `t = n/f_s`

Every node produces **one sample per tick.**

---

### 2. High-Level DSP Graph
```text
[LFO(s)] → [Modulator Bank] → [Carrier Osc(s)] → [Multiplier] → [Envelope] → [Layer Output] → (repeat per layer) → [Output] ← [Mixer/Sum]
```

---

### 3. Oscillator Nodes (Carriers)

#### 3.1 Sine Oscillator
**State:**
* Phase `ϕ`

**Update per sample:**
```mathematics
ϕ_{n+1} = ϕ_n + 2π(f_c / f_s)
```

**Output:**
```mathematics
C[n] = sin(ϕ_n)
```

**Notes:**
* Phase wraps at `2π`
* Frequency changes **must be smoothed** to prevent clicks
* Use float-precision phase accumulation to prevent drift in long sessions

#### 3.2 Harmonic Oscillator
Multiple sine oscillators summed:
```mathematics
C[n] = ∑(k=1 to K) a_k sin(kϕ_n)
```
**Implementation:**
* One phase accumulator
* Multiple sine evaluations or lookup table
* Pre-computed harmonic weights `a_k`

---

### 4. LFO Nodes (Low-Frequency Oscillators)
Same oscillator structure as carriers, but:
* `f_m ≪ 20Hz` sub-audio
* Output range normalized to `[-1, 1]`

**Common waveforms:**
* Sine (default – smoothest)
* Triangle (slightly more "organic")
* Smoothed square (isochronic-style)

**Example output:**
```mathematics
L[n] = sin(2πf_m n / f_s)
```

---

### 5. Modulator Bank
Takes **LFO** output and converts it into **multipliers.**

#### 5.1 Smooth AM
**Input:** `L[n] ∈ [-1, 1]`

**Transform:**
```mathematics
M[n] = 1 + α · L[n]
```

**Guarantees:**
* `M[n] ≥ 0` no polarity inversion
* Bounded output range

#### 5.2 Isochronic Gate
**Input:** Square LFO

**Transform:**
```mathematics
       ⎧ 1   L[n] > 0
M[n] = ⎨
       ⎩ 0   L[n] ≤ 0
```

**Then:**
* Pass through slew limiter or low-pass filter
* Prevents clicks and harsh transients

---

### 6. Envelope Node (macro control)
This is **not ADSR** in the musical sense. It's much slower.

**State machine:**
* Attack phase
* Sustain phase
* Release phase

#### 6.1 Attack Phase
```mathematics
E[n] = 1 - e^(-n / (τ_a f_s))
```

#### 6.2 Release Phase
```mathematics
E[n] = e^(-(n - n_off) / (τ_r f_s))
```
**Key property:**
* Envelope is **monotonic** (no overshoot)
* No fast edges

---

### 7. Layer Output Node
This is where the math becomes literal:
```mathematics
Y[n] = C[n] · M[n] · E[n]
```
Each layer is **self-contained:**
* One carrier oscillator
* One modulation path
* One envelope generator

**No shared state across layers.** This is intentional for stability.

---

### 8. Noise Layer (Optional)
Pink ot brown noise generator:
```mathematics
Y_noise[n] = E[n] · noise()
```
**Purpose:**
* Mask tonal fatigue
* Reduce perceived repetition
* Add textural richness

---

### 9. Mixer Node
Summation with normalization:
```mathematics
Y_mix[n] = ∑(i=1 to N) w_i Y_i[n]
```
**Then:**
```mathematics
Y_out[n] = clamp(Y_mix[n], -1, 1)
```
**Better approach:**
* Soft limiter (tanh or atan)
* Reserve headroom (-6dB typical)

---

### 10. Stereo Graph (Binaural Effects)
For stereo signals with frequency offset:
```text
Carrier_L → Envelope → Left Mixer
Carrier_R → Envelope → Right Mixer
```
**With:**
```mathematics
f_R = f_L + Δf
```
Everything else is identical. The perceived "beat" emerges from the frequency difference:
```mathematics
f_beat = |f_R - f_L|
```
**Important:** No modulation exists in the waveform itself. The beat is a **neural interference effect.**

---

### 11. Control-Rate vs Audio-Rate
**Important design boundary:**
* **Oscillators, mixers** → audio-rate (48kHz)
* **LFOs, envelopes** → can be control-rate (e.g. 100Hz or decimated)
* **Parameter smoothing** → control-rate

This saves CPU and improves stability on mobile devices.

---

### 12. Graph Invariants (enforced rules)
* No node introduces discontinuities
* No parameter jumps without smoothing
* All multipliers remain bounded
* Layers are additive, not interdependent

---

## Mobile Audio Constraints

### 1. Platform Reality
On Android and iOS, we **do not own** the audio device. We feed buffers to the OS on its schedule.

**This implies:**
* Must be real-time safe
* No allocations in audio callback
* No locks
* No LINQ, no events, no async inside DSP
* Deterministic CPU usage per buffer

**Our DSP graph must be:**
* Pull-based
* Stateless per sample (except phase accumulators)
* Minimal mutable state

---

### 2. Platform Strategy
With C# .NET and MAUI:
* **.NET MAUI** for cross-platform UI
* **Platform-native audio backends**, bridged into shared DSP code

**Typical choices:**
* Android → `AudioTrack` (low-latency mode)
* iOS → `AVAudioEngine`/`AVAudioSourceNode`

**Our DSP lives in:**
> Pure .NET standard-compatible code with zero platform dependencies and no UI knowledge.

---

### 3. Separation of Concerns (non-negotiable)
```text
[MAUI UI Layer] → [Control/Params (thread-safe, smoothed)] → [DSP Engine (pure math)] → [Platform Audio API]
```
**The DSP engine:**
* Knows nothing about Android or iOS
* Only outputs `float` samples
* Is driven by a "render buffer" call

---

### 4. Audio Callback Contract
Platform asks for buffers:
```csharp
public void Process(Span<float> buffer)
{
 for (int i = 0; i < buffer.Length; i++)
 {
  buffer[i] = _mixer.GenerateSample();
 }
}
```
This is the **only** place where samples are generated.

---

### 5. Parameter Changes (UI → DSP)
**Never write directly into DSP nodes from UI.**

**Instead:**
* UI writes to a thread-safe parameter store
* DSP reads smoothed values

**Example:**
```csharp
carrierFrequency += (targetFrequency - carrierFrequency) * 0.001f;
```
No locks. No atomics if we can avoid them. Smoothing absorbs jitter.

---

### 6. Battery & Thermal Considerations
Mobile devices punish:
* Excessive trigger calls (use lookup tables)
* Per-sample allocations (pre-allocate everything)
* High-rate modulation (use control-rate decimation)

**Mitigations:**
* Lookup tables for sine
* Control-rate LFOs (update every 16-64 samples)
* Few layers (2-4 maximum)
* Avoid stereo unless needed (doubles CPU)

This engine can run **for hours** without draining a phone if done right.

---

### 7. Error Handling
**In audio callback:**
* Never throw exceptions
* Store error state, report later
* Silence output on error
* Log on background thread only, never in hot path

**Example:**
```csharp
try
{
 // Render audio
}
catch (Exception ex)
{
 _lastError = ex; // Volatile write
 buffer.Clear();   // Silence

 // Report asynchronously
 ThreadPool.QueueUserWorkItem(_ => LogError(ex));
}
```

---

### 8. What Is Being Built (summary)
A system with:
* Deterministic DSP graph
* Mobile-safe execution model
* Clean separation between sound design and UI
* Capability to express any AM/FM/layered signal
* No allocations in hot path
* No domain assumptions in Core layer
